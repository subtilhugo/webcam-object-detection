# üîç D√©tection d'Objets en Temps R√©el par Webcam

Une interface web moderne pour identifier des objets en temps r√©el en utilisant votre webcam avec l'intelligence artificielle. Supporte Llama.cpp (local, gratuit) et OpenAI (cloud, payant).

## ‚ú® Fonctionnalit√©s

- üé• **D√©tection en temps r√©el** via webcam
- ü§ñ **Support multi-mod√®les** : Llama.cpp et OpenAI
- üé® **Interface moderne** et responsive
- ‚ö° **Performance optimis√©e** avec gestion des intervalles
- üîß **Configuration flexible** pour diff√©rents mod√®les
- üì± **Design responsive** pour mobile et desktop

## üöÄ Installation Rapide

### Option 1 : Llama.cpp (Recommand√© - Gratuit)

1. **Installer Llama.cpp** :
   ```bash
   chmod +x install_llama.sh
   ./install_llama.sh
   ```

2. **D√©marrer le serveur Llama.cpp** :
   ```bash
   chmod +x start_llama_server.sh
   ./start_llama_server.sh
   ```

3. **Lancer l'interface web** :
   ```bash
   python3 server.py
   ```

### Option 2 : OpenAI (Payant)

1. **Obtenir une cl√© API OpenAI** :
   - Allez sur [OpenAI Platform](https://platform.openai.com/api-keys)
   - Cr√©ez une nouvelle cl√© API

2. **Lancer l'interface web** :
   ```bash
   python3 server.py
   ```

3. **Configurer dans l'interface** :
   - S√©lectionnez "OpenAI"
   - Entrez votre cl√© API
   - Choisissez un mod√®le (GPT-4o recommand√©)

## üìã Pr√©requis

### Pour Llama.cpp :
- macOS (test√© sur macOS 14+)
- Homebrew
- Au moins 8GB de RAM
- GPU recommand√© (Metal pour macOS)

### Pour OpenAI :
- Connexion internet
- Cl√© API OpenAI valide
- Compte OpenAI avec cr√©dits

## üéØ Utilisation

1. **Ouvrez l'interface** : http://localhost:8000
2. **Choisissez votre mod√®le** : Llama.cpp ou OpenAI
3. **Configurez les param√®tres** :
   - URL du serveur (pour Llama.cpp)
   - Cl√© API (pour OpenAI)
   - Instructions personnalis√©es
   - Intervalle de capture
4. **Cliquez sur "D√©marrer"** et accordez les permissions de cam√©ra
5. **Profitez** de la d√©tection d'objets en temps r√©el !

## ‚öôÔ∏è Configuration Avanc√©e

### Llama.cpp

**Mod√®les disponibles** :
- `SmolVLM-500M-Instruct-GGUF` (recommand√©, rapide)
- `llava-v1.5-7b` (plus pr√©cis, plus lent)
- `bakllava-1` (bon √©quilibre)

**Options de serveur** :
```bash
# Utiliser le GPU
./llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF -ngl 99

# Changer le port
./llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF -p 8080

# Plus de m√©moire
./llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF -c 4096
```

### OpenAI

**Mod√®les disponibles** :
- `gpt-4o` (recommand√©, tr√®s pr√©cis)
- `gpt-4o-mini` (rapide, √©conomique)
- `gpt-4-vision-preview` (sp√©cialis√© vision)

## üîß D√©pannage

### Probl√®mes de cam√©ra
- **Erreur de permissions** : Assurez-vous d'accorder l'acc√®s √† la cam√©ra
- **Cam√©ra non d√©tect√©e** : V√©rifiez que votre webcam fonctionne
- **HTTPS requis** : Utilisez localhost ou HTTPS

### Probl√®mes Llama.cpp
- **Serveur non accessible** : V√©rifiez que llama-server est en cours d'ex√©cution
- **Erreur de compilation** : V√©rifiez les d√©pendances (cmake, ninja)
- **M√©moire insuffisante** : R√©duisez la taille du contexte (-c 2048)

### Probl√®mes OpenAI
- **Cl√© API invalide** : V√©rifiez votre cl√© sur OpenAI Platform
- **Quota d√©pass√©** : V√©rifiez vos cr√©dits OpenAI
- **Erreur de r√©seau** : V√©rifiez votre connexion internet

## üìÅ Structure du Projet

```
webcam-object-detection/
‚îú‚îÄ‚îÄ index.html          # Interface web principale
‚îú‚îÄ‚îÄ server.py           # Serveur web Python
‚îú‚îÄ‚îÄ install_llama.sh    # Script d'installation Llama.cpp
‚îú‚îÄ‚îÄ start_llama_server.sh # Script de d√©marrage serveur
‚îú‚îÄ‚îÄ README.md           # Ce fichier
‚îî‚îÄ‚îÄ llama.cpp/          # Dossier Llama.cpp (apr√®s installation)
```

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :
- Signaler des bugs
- Proposer des am√©liorations
- Ajouter de nouveaux mod√®les
- Am√©liorer l'interface

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

## üôè Remerciements

- [llama.cpp](https://github.com/ggml-org/llama.cpp) - Pour l'infrastructure locale
- [SmolVLM](https://github.com/ggml-org/SmolVLM-500M-Instruct-GGUF) - Pour le mod√®le de vision
- [OpenAI](https://openai.com) - Pour les mod√®les cloud
- [ngxson/smolvlm-realtime-webcam](https://github.com/ngxson/smolvlm-realtime-webcam) - Pour l'inspiration initiale

---

**üéâ Amusez-vous bien avec votre d√©tection d'objets en temps r√©el !**
