#!/bin/bash

echo "ğŸš€ DÃ©marrage du serveur Llama.cpp pour la dÃ©tection d'objets"
echo "============================================================"

# VÃ©rifier si llama.cpp est installÃ©
if [ ! -d "llama.cpp" ]; then
    echo "âŒ llama.cpp non trouvÃ©. ExÃ©cutez d'abord: ./install_llama.sh"
    exit 1
fi

# Aller dans le rÃ©pertoire build
cd llama.cpp/build

# VÃ©rifier si le serveur existe
if [ ! -f "llama-server" ]; then
    echo "âŒ Serveur llama-server non trouvÃ©. VÃ©rifiez l'installation."
    exit 1
fi

echo "âœ… Serveur trouvÃ©, dÃ©marrage..."
echo "ğŸŒ Le serveur sera accessible sur: http://localhost:8080"
echo "ğŸ“¹ L'interface web sera accessible sur: http://localhost:8000"
echo ""
echo "â¹ï¸  Appuyez sur Ctrl+C pour arrÃªter le serveur"
echo ""

# DÃ©marrer le serveur avec SmolVLM
./llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF -ngl 99 -p 8080